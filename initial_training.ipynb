{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configurazione della cartella base contenente le img per il train\n",
    "\n",
    "Tutte le immagini sono inserite all'interno di un bucket S3, organizzato nel seguente modo:\n",
    "\n",
    "    completeDataset\n",
    "    ├── redcard\n",
    "    |  ├── redcard.1.jpg\n",
    "    |  ├── redcard.2.jpg\n",
    "    |  └── . . .\n",
    "    ├── yellowcard\n",
    "    |  ├── ycard.1.jpg\n",
    "    |  ├── ycard.2.jpg\n",
    "    |  └── . . .\n",
    "    ├── change\n",
    "    |  ├── change.1.jpg\n",
    "    |  ├── change.2.jpg\n",
    "    |  └── . . .\n",
    "    └── . . ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Bucket S3\n",
    "bucket_name = 'ahlimgdata'\n",
    "\n",
    "#prefisso cartella contenente le sottocartelle delle immagini del dataset (una per label)\n",
    "dataset_name = 'completeDataset'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Impostazione dell'ambiente\n",
    "\n",
    "Settiamo i collegamenti e l'autenticazione ai servizi AWS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sagemaker\n",
    "import cv2\n",
    "from sagemaker import get_execution_role\n",
    "from sagemaker.amazon.amazon_estimator import get_image_uri\n",
    "\n",
    "role = get_execution_role()\n",
    "sess = sagemaker.Session()\n",
    "\n",
    "#immagine build-in dell'algoritmo di classificazione\n",
    "training_image = get_image_uri(sess.boto_region_name, 'image-classification', repo_version=\"latest\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparazione dei dati per il modello\n",
    "\n",
    "Prima di lanciare il train sul modello bisogna:\n",
    "\n",
    "* Creare alcuni file che insegnano a SageMaker le immagini di ciascuna delle label\n",
    "* Caricare questi file addizionali in S3\n",
    "* Configurare il modello nell'usare questi file per il train el al validazione"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "L'immagine dell'algoritmo per la classificazione ha bisogno di capire la relazione immagine->label. Per la creazione di questi file utilizziamo file LST o RecorI, in particolare usiamo lo script python im2rec.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: BASE_DIR=/tmp\n",
      "env: S3_DATA_BUCKET_NAME=ahlimgdata\n",
      "env: DATASET_NAME=completeDataset\n",
      "env: IM2REC=/home/ec2-user/anaconda3/envs/mxnet_p36/lib/python3.6/site-packages/mxnet/tools/im2rec.py\n"
     ]
    }
   ],
   "source": [
    "# Cerchiamo im2rec nel nostro ambiente e settiamo alcune variabili\n",
    "\n",
    "base_dir = '/tmp'\n",
    "\n",
    "%env BASE_DIR = $base_dir\n",
    "%env S3_DATA_BUCKET_NAME = $bucket_name\n",
    "%env DATASET_NAME = $dataset_name\n",
    "\n",
    "import sys,os\n",
    "\n",
    "suffix = '/mxnet/tools/im2rec.py'\n",
    "im2rec = list(filter( (lambda x: os.path.isfile(x + suffix )), sys.path))[0] + suffix\n",
    "%env IM2REC = $im2rec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prendiamo le immagini per il train da S3\n",
    "\n",
    "Dobbiamo creare i file RecordIO per il train e la validazione e dobbiamo scaricarle nel filesystem locale."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Raccoglimento delle immagini da S3\n",
    "!aws s3 sync s3://$S3_DATA_BUCKET_NAME/$DATASET_NAME $BASE_DIR/$DATASET_NAME --quiet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adattamento img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# %%bash\n",
    "# CATEGORIES = [\"change\", \"redcard\", \"yellowcard\"]\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "categories = !ls $BASE_DIR/$DATASET_NAME\n",
    "suffix = base_dir+\"/\"+dataset_name\n",
    "\n",
    "for category in categories:\n",
    "    label_path = os.path.join(suffix, category)\n",
    "    for img in os.listdir(label_path):\n",
    "        i = cv2.imread(os.path.join(label_path,img))\n",
    "        new_img = cv2.resize(i, (224,224))\n",
    "        cv2.imwrite(os.path.join(label_path,img),new_img)\n",
    "\n",
    "\n",
    "# /home/ec2-user/anaconda3/bin/python -m pip install --upgrade pip\n",
    "# pip install opencv-python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creazione dei file RecordIO del training\n",
    "\n",
    "Lo script im2rec.py può creare file LST o RecodIO."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creazione LST file\n",
      "Classi label:\n",
      "change 0\n",
      "esultanza 1\n",
      "game 2\n",
      "goal 3\n",
      "guardalinee 4\n",
      "palo 5\n",
      "punizione 6\n",
      "redcard 7\n",
      "rigore 8\n",
      "var 9\n",
      "yellowcard 10\n",
      "Creazione RecordIO files\n",
      "Creating .rec file from /tmp/completeDataset_train.lst in /tmp\n",
      "time: 0.004594326019287109  count: 0\n",
      "Creating .rec file from /tmp/completeDataset_test.lst in /tmp\n",
      "time: 0.014521121978759766  count: 0\n",
      "-rw-rw-r-- 1 ec2-user ec2-user 5.7M May 21 14:58 completeDataset_test.rec\n",
      "-rw-rw-r-- 1 ec2-user ec2-user  14M May 21 14:58 completeDataset_train.rec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "rm: cannot remove ‘*.rec’: No such file or directory\n",
      "rm: cannot remove ‘*.lst’: No such file or directory\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "#Utilizziamo im2rec.py per convertire le nostre immagini in RecordIO file\n",
    "\n",
    "#Puliamo la nostra dir di lavoro esistente dai file LST e REC\n",
    "\n",
    "cd $BASE_DIR\n",
    "rm *.rec\n",
    "rm *.lst\n",
    "\n",
    "# Come prima cosa dobbiamo creare due LST file (training e test), attenzione a posizionare le img nelle classi corrette\n",
    "# dobbiamo includere anche la lista di tutte le classi di label\n",
    "\n",
    "echo \"Creazione LST file\"\n",
    "python $IM2REC --list --recursive --pass-through --test-ratio=0.3 --train-ratio=0.7 $DATASET_NAME $DATASET_NAME > ${DATASET_NAME}_classes\n",
    "\n",
    "echo \"Classi label:\"\n",
    "cat ${DATASET_NAME}_classes\n",
    "\n",
    "# Creazione dei file RecordIO dai file LST\n",
    "echo \"Creazione RecordIO files\"\n",
    "python $IM2REC --num-thread=4 ${DATASET_NAME}_train.lst $DATASET_NAME\n",
    "python $IM2REC --num-thread=4 ${DATASET_NAME}_test.lst $DATASET_NAME\n",
    "ls -lh *.rec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Caricamento dei dati di training e test (RecordIO files)\n",
    "\n",
    "Salvataggio dei file in S3 così SageMaker può utilizzarli per il training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "delete: s3://sagemaker-us-east-2-693949087897/completeDataset/train/completeDataset_train.rec\n",
      "delete: s3://sagemaker-us-east-2-693949087897/completeDataset/validation/completeDataset_test.rec\n",
      "upload: ../../../tmp/completeDataset_train.rec to s3://sagemaker-us-east-2-693949087897/completeDataset/train/completeDataset_train.rec\n",
      "upload: ../../../tmp/completeDataset_test.rec to s3://sagemaker-us-east-2-693949087897/completeDataset/validation/completeDataset_test.rec\n"
     ]
    }
   ],
   "source": [
    "#Caricamento dei file nel bucket S3 che la sessione di SageMaker sta usando\n",
    "bucket = sess.default_bucket()\n",
    "\n",
    "s3train_path = 's3://{}/{}/train/'.format(bucket, dataset_name)\n",
    "s3validation_path = 's3://{}/{}/validation/'.format(bucket, dataset_name)\n",
    "\n",
    "# Pulizia dait pre-esistenti\n",
    "!aws s3 rm s3://{bucket}/{dataset_name}/train --recursive\n",
    "!aws s3 rm s3://{bucket}/{dataset_name}/validation --recursive\n",
    "\n",
    "# Caricamento dei file rec nei canali di train e validazione\n",
    "!aws s3 cp /tmp/{dataset_name}_train.rec $s3train_path\n",
    "!aws s3 cp /tmp/{dataset_name}_test.rec $s3validation_path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configurazione dei dati da usare per il training\n",
    "\n",
    "Diciamo a SageMaker dove trovare i file RecordIo da usare per il training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = sagemaker.session.s3_input(\n",
    "    s3train_path,\n",
    "    distribution = 'FullyReplicated',\n",
    "    content_type = 'application/x-recordio',\n",
    "    s3_data_type = 'S3Prefix'\n",
    ")\n",
    "\n",
    "validation_data = sagemaker.session.s3_input(\n",
    "    s3validation_path,\n",
    "    distribution = 'FullyReplicated',\n",
    "    content_type = 'application/x-recordio',\n",
    "    s3_data_type = 'S3Prefix'\n",
    ")\n",
    "\n",
    "data_channels = {'train' : train_data, 'validation' : validation_data}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training\n",
    "\n",
    "#### Creazione di un classificatore di immagini con una configurazione base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s3://sagemaker-us-east-2-693949087897/completeDataset/output\n"
     ]
    }
   ],
   "source": [
    "s3_output_location = 's3://{}/{}/output'.format(bucket, dataset_name)\n",
    "\n",
    "image_classifier = sagemaker.estimator.Estimator(\n",
    "    training_image,\n",
    "    role,\n",
    "    train_instance_count = 1,\n",
    "    train_instance_type = 'ml.p2.xlarge',\n",
    "    output_path = s3_output_location,\n",
    "    sagemaker_session = sess\n",
    ")\n",
    "\n",
    "print(s3_output_location)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Impostazione di alcuni iperparametri"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'use_pretrained_model': 1,\n",
       " 'image_shape': '3,224,224',\n",
       " 'num_classes': 11,\n",
       " 'num_training_samples': 600,\n",
       " 'learning_rate': 0.001,\n",
       " 'mini_batch_size': 5}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_classes=! ls -l {base_dir}/{dataset_name} | wc -l\n",
    "num_classes=int(num_classes[0]) - 1\n",
    "\n",
    "num_training_samples=! cat {base_dir}/{dataset_name}_train.lst | wc -l\n",
    "num_training_samples = int(num_training_samples[0])\n",
    "\n",
    "# Tuning degli iperparametri\n",
    "base_hyperparameters=dict(\n",
    "    use_pretrained_model=1,\n",
    "    image_shape='3,224,224',\n",
    "    num_classes=num_classes,\n",
    "    num_training_samples=num_training_samples,\n",
    ")\n",
    "\n",
    "# Iperparametri che aiutano il successo del modello\n",
    "hyperparameters={\n",
    "    **base_hyperparameters, \n",
    "    **dict(\n",
    "        learning_rate=0.001,\n",
    "        mini_batch_size=5,\n",
    "    )\n",
    "}\n",
    "\n",
    "\n",
    "image_classifier.set_hyperparameters(**hyperparameters)\n",
    "\n",
    "hyperparameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inizio del train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-05-21 14:58:06 Starting - Starting the training job...\n",
      "2020-05-21 14:58:08 Starting - Launching requested ML instances.........\n",
      "2020-05-21 14:59:38 Starting - Preparing the instances for training.........\n",
      "2020-05-21 15:01:19 Downloading - Downloading input data...\n",
      "2020-05-21 15:01:56 Training - Downloading the training image......\n",
      "2020-05-21 15:02:51 Training - Training image download completed. Training in progress.\u001b[34mDocker entrypoint called with argument(s): train\u001b[0m\n",
      "\u001b[34m[05/21/2020 15:02:54 INFO 140130713106240] Reading default configuration from /opt/amazon/lib/python2.7/site-packages/image_classification/default-input.json: {u'beta_1': 0.9, u'gamma': 0.9, u'beta_2': 0.999, u'optimizer': u'sgd', u'use_pretrained_model': 0, u'eps': 1e-08, u'epochs': 30, u'lr_scheduler_factor': 0.1, u'num_layers': 152, u'image_shape': u'3,224,224', u'precision_dtype': u'float32', u'mini_batch_size': 32, u'weight_decay': 0.0001, u'learning_rate': 0.1, u'momentum': 0}\u001b[0m\n",
      "\u001b[34m[05/21/2020 15:02:54 INFO 140130713106240] Merging with provided configuration from /opt/ml/input/config/hyperparameters.json: {u'learning_rate': u'0.001', u'num_training_samples': u'600', u'image_shape': u'3,224,224', u'mini_batch_size': u'5', u'use_pretrained_model': u'1', u'num_classes': u'11'}\u001b[0m\n",
      "\u001b[34m[05/21/2020 15:02:54 INFO 140130713106240] Final configuration: {u'beta_1': 0.9, u'gamma': 0.9, u'beta_2': 0.999, u'optimizer': u'sgd', u'use_pretrained_model': u'1', u'num_classes': u'11', u'eps': 1e-08, u'epochs': 30, u'lr_scheduler_factor': 0.1, u'num_layers': 152, u'image_shape': u'3,224,224', u'precision_dtype': u'float32', u'mini_batch_size': u'5', u'weight_decay': 0.0001, u'learning_rate': u'0.001', u'momentum': 0, u'num_training_samples': u'600'}\u001b[0m\n",
      "\u001b[34m[05/21/2020 15:02:54 INFO 140130713106240] Searching for .rec files in /opt/ml/input/data/train.\u001b[0m\n",
      "\u001b[34m[05/21/2020 15:02:54 INFO 140130713106240] Searching for .rec files in /opt/ml/input/data/validation.\u001b[0m\n",
      "\u001b[34m[05/21/2020 15:02:54 INFO 140130713106240] use_pretrained_model: 1\u001b[0m\n",
      "\u001b[34m[05/21/2020 15:02:54 INFO 140130713106240] multi_label: 0\u001b[0m\n",
      "\u001b[34m[05/21/2020 15:02:54 INFO 140130713106240] Using pretrained model for initializing weights and transfer learning.\u001b[0m\n",
      "\u001b[34m[05/21/2020 15:02:54 INFO 140130713106240] ---- Parameters ----\u001b[0m\n",
      "\u001b[34m[05/21/2020 15:02:54 INFO 140130713106240] num_layers: 152\u001b[0m\n",
      "\u001b[34m[05/21/2020 15:02:54 INFO 140130713106240] data type: <type 'numpy.float32'>\u001b[0m\n",
      "\u001b[34m[05/21/2020 15:02:54 INFO 140130713106240] epochs: 30\u001b[0m\n",
      "\u001b[34m[05/21/2020 15:02:54 INFO 140130713106240] optimizer: sgd\u001b[0m\n",
      "\u001b[34m[05/21/2020 15:02:54 INFO 140130713106240] momentum: 0.9\u001b[0m\n",
      "\u001b[34m[05/21/2020 15:02:54 INFO 140130713106240] weight_decay: 0.0001\u001b[0m\n",
      "\u001b[34m[05/21/2020 15:02:54 INFO 140130713106240] learning_rate: 0.001\u001b[0m\n",
      "\u001b[34m[05/21/2020 15:02:54 INFO 140130713106240] num_training_samples: 600\u001b[0m\n",
      "\u001b[34m[05/21/2020 15:02:54 INFO 140130713106240] mini_batch_size: 5\u001b[0m\n",
      "\u001b[34m[05/21/2020 15:02:54 INFO 140130713106240] image_shape: 3,224,224\u001b[0m\n",
      "\u001b[34m[05/21/2020 15:02:54 INFO 140130713106240] num_classes: 11\u001b[0m\n",
      "\u001b[34m[05/21/2020 15:02:54 INFO 140130713106240] augmentation_type: None\u001b[0m\n",
      "\u001b[34m[05/21/2020 15:02:54 INFO 140130713106240] kv_store: device\u001b[0m\n",
      "\u001b[34m[05/21/2020 15:02:54 INFO 140130713106240] checkpoint_frequency not set, will store the best model\u001b[0m\n",
      "\u001b[34m[05/21/2020 15:02:54 INFO 140130713106240] --------------------\u001b[0m\n",
      "\u001b[34m[15:02:54] /opt/brazil-pkg-cache/packages/AIAlgorithmsMXNet/AIAlgorithmsMXNet-1.3.x_ecl_Cuda_10.1.x.2633.0/AL2012/generic-flavor/src/src/nnvm/legacy_json_util.cc:209: Loading symbol saved by previous version v0.8.0. Attempting to upgrade...\u001b[0m\n",
      "\u001b[34m[15:02:54] /opt/brazil-pkg-cache/packages/AIAlgorithmsMXNet/AIAlgorithmsMXNet-1.3.x_ecl_Cuda_10.1.x.2633.0/AL2012/generic-flavor/src/src/nnvm/legacy_json_util.cc:217: Symbol successfully upgraded!\u001b[0m\n",
      "\u001b[34m[05/21/2020 15:02:56 INFO 140130713106240] Setting number of threads: 3\u001b[0m\n",
      "\u001b[34m[15:03:02] /opt/brazil-pkg-cache/packages/AIAlgorithmsMXNet/AIAlgorithmsMXNet-1.3.x_ecl_Cuda_10.1.x.2633.0/AL2012/generic-flavor/src/src/operator/nn/./cudnn/./cudnn_algoreg-inl.h:97: Running performance tests to find the best convolution algorithm, this can take a while... (setting env variable MXNET_CUDNN_AUTOTUNE_DEFAULT to 0 to disable)\u001b[0m\n",
      "\u001b[34m[05/21/2020 15:03:17 INFO 140130713106240] Epoch[0] Batch [20]#011Speed: 6.275 samples/sec#011accuracy=0.295238\u001b[0m\n",
      "\u001b[34m[05/21/2020 15:03:24 INFO 140130713106240] Epoch[0] Batch [40]#011Speed: 8.715 samples/sec#011accuracy=0.375610\u001b[0m\n",
      "\u001b[34m[05/21/2020 15:03:31 INFO 140130713106240] Epoch[0] Batch [60]#011Speed: 10.010 samples/sec#011accuracy=0.429508\u001b[0m\n",
      "\u001b[34m[05/21/2020 15:03:38 INFO 140130713106240] Epoch[0] Batch [80]#011Speed: 10.817 samples/sec#011accuracy=0.464198\u001b[0m\n",
      "\u001b[34m[05/21/2020 15:03:45 INFO 140130713106240] Epoch[0] Batch [100]#011Speed: 11.365 samples/sec#011accuracy=0.485149\u001b[0m\n",
      "\u001b[34m[05/21/2020 15:03:52 INFO 140130713106240] Epoch[0] Train-accuracy=0.506667\u001b[0m\n",
      "\u001b[34m[05/21/2020 15:03:52 INFO 140130713106240] Epoch[0] Time cost=50.697\u001b[0m\n",
      "\u001b[34m[05/21/2020 15:03:58 INFO 140130713106240] Epoch[0] Validation-accuracy=0.773077\u001b[0m\n",
      "\u001b[34m[05/21/2020 15:03:59 INFO 140130713106240] Storing the best model with validation accuracy: 0.773077\u001b[0m\n",
      "\u001b[34m[05/21/2020 15:03:59 INFO 140130713106240] Saved checkpoint to \"/opt/ml/model/image-classification-0001.params\"\u001b[0m\n",
      "\u001b[34m[05/21/2020 15:04:07 INFO 140130713106240] Epoch[1] Batch [20]#011Speed: 13.050 samples/sec#011accuracy=0.790476\u001b[0m\n",
      "\u001b[34m[05/21/2020 15:04:14 INFO 140130713106240] Epoch[1] Batch [40]#011Speed: 13.602 samples/sec#011accuracy=0.795122\u001b[0m\n",
      "\u001b[34m[05/21/2020 15:04:21 INFO 140130713106240] Epoch[1] Batch [60]#011Speed: 13.782 samples/sec#011accuracy=0.786885\u001b[0m\n",
      "\u001b[34m[05/21/2020 15:04:28 INFO 140130713106240] Epoch[1] Batch [80]#011Speed: 13.871 samples/sec#011accuracy=0.814815\u001b[0m\n",
      "\u001b[34m[05/21/2020 15:04:35 INFO 140130713106240] Epoch[1] Batch [100]#011Speed: 13.934 samples/sec#011accuracy=0.821782\u001b[0m\n",
      "\u001b[34m[05/21/2020 15:04:41 INFO 140130713106240] Epoch[1] Train-accuracy=0.816667\u001b[0m\n",
      "\u001b[34m[05/21/2020 15:04:41 INFO 140130713106240] Epoch[1] Time cost=42.566\u001b[0m\n",
      "\u001b[34m[05/21/2020 15:04:47 INFO 140130713106240] Epoch[1] Validation-accuracy=0.819608\u001b[0m\n",
      "\u001b[34m[05/21/2020 15:04:48 INFO 140130713106240] Storing the best model with validation accuracy: 0.819608\u001b[0m\n",
      "\u001b[34m[05/21/2020 15:04:48 INFO 140130713106240] Saved checkpoint to \"/opt/ml/model/image-classification-0002.params\"\u001b[0m\n",
      "\u001b[34m[05/21/2020 15:04:56 INFO 140130713106240] Epoch[2] Batch [20]#011Speed: 13.034 samples/sec#011accuracy=0.904762\u001b[0m\n",
      "\u001b[34m[05/21/2020 15:05:03 INFO 140130713106240] Epoch[2] Batch [40]#011Speed: 13.562 samples/sec#011accuracy=0.907317\u001b[0m\n",
      "\u001b[34m[05/21/2020 15:05:10 INFO 140130713106240] Epoch[2] Batch [60]#011Speed: 13.740 samples/sec#011accuracy=0.901639\u001b[0m\n",
      "\u001b[34m[05/21/2020 15:05:17 INFO 140130713106240] Epoch[2] Batch [80]#011Speed: 13.832 samples/sec#011accuracy=0.888889\u001b[0m\n",
      "\u001b[34m[05/21/2020 15:05:24 INFO 140130713106240] Epoch[2] Batch [100]#011Speed: 13.874 samples/sec#011accuracy=0.893069\u001b[0m\n",
      "\u001b[34m[05/21/2020 15:05:31 INFO 140130713106240] Epoch[2] Train-accuracy=0.890000\u001b[0m\n",
      "\u001b[34m[05/21/2020 15:05:31 INFO 140130713106240] Epoch[2] Time cost=42.751\u001b[0m\n",
      "\u001b[34m[05/21/2020 15:05:37 INFO 140130713106240] Epoch[2] Validation-accuracy=0.850000\u001b[0m\n",
      "\u001b[34m[05/21/2020 15:05:37 INFO 140130713106240] Storing the best model with validation accuracy: 0.850000\u001b[0m\n",
      "\u001b[34m[05/21/2020 15:05:38 INFO 140130713106240] Saved checkpoint to \"/opt/ml/model/image-classification-0003.params\"\u001b[0m\n",
      "\u001b[34m[05/21/2020 15:05:45 INFO 140130713106240] Epoch[3] Batch [20]#011Speed: 12.960 samples/sec#011accuracy=0.914286\u001b[0m\n",
      "\u001b[34m[05/21/2020 15:05:52 INFO 140130713106240] Epoch[3] Batch [40]#011Speed: 13.542 samples/sec#011accuracy=0.946341\u001b[0m\n",
      "\u001b[34m[05/21/2020 15:05:59 INFO 140130713106240] Epoch[3] Batch [60]#011Speed: 13.723 samples/sec#011accuracy=0.944262\u001b[0m\n",
      "\u001b[34m[05/21/2020 15:06:07 INFO 140130713106240] Epoch[3] Batch [80]#011Speed: 13.832 samples/sec#011accuracy=0.948148\u001b[0m\n",
      "\u001b[34m[05/21/2020 15:06:14 INFO 140130713106240] Epoch[3] Batch [100]#011Speed: 13.854 samples/sec#011accuracy=0.954455\u001b[0m\n",
      "\u001b[34m[05/21/2020 15:06:20 INFO 140130713106240] Epoch[3] Train-accuracy=0.951667\u001b[0m\n",
      "\u001b[34m[05/21/2020 15:06:20 INFO 140130713106240] Epoch[3] Time cost=42.811\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m[05/21/2020 15:06:26 INFO 140130713106240] Epoch[3] Validation-accuracy=0.866667\u001b[0m\n",
      "\u001b[34m[05/21/2020 15:06:27 INFO 140130713106240] Storing the best model with validation accuracy: 0.866667\u001b[0m\n",
      "\u001b[34m[05/21/2020 15:06:27 INFO 140130713106240] Saved checkpoint to \"/opt/ml/model/image-classification-0004.params\"\u001b[0m\n",
      "\u001b[34m[05/21/2020 15:06:35 INFO 140130713106240] Epoch[4] Batch [20]#011Speed: 13.023 samples/sec#011accuracy=0.942857\u001b[0m\n",
      "\u001b[34m[05/21/2020 15:06:42 INFO 140130713106240] Epoch[4] Batch [40]#011Speed: 13.577 samples/sec#011accuracy=0.951220\u001b[0m\n",
      "\u001b[34m[05/21/2020 15:06:49 INFO 140130713106240] Epoch[4] Batch [60]#011Speed: 13.754 samples/sec#011accuracy=0.963934\u001b[0m\n",
      "\u001b[34m[05/21/2020 15:06:56 INFO 140130713106240] Epoch[4] Batch [80]#011Speed: 13.843 samples/sec#011accuracy=0.967901\u001b[0m\n",
      "\u001b[34m[05/21/2020 15:07:03 INFO 140130713106240] Epoch[4] Batch [100]#011Speed: 13.908 samples/sec#011accuracy=0.966337\u001b[0m\n",
      "\u001b[34m[05/21/2020 15:07:10 INFO 140130713106240] Epoch[4] Train-accuracy=0.968333\u001b[0m\n",
      "\u001b[34m[05/21/2020 15:07:10 INFO 140130713106240] Epoch[4] Time cost=42.650\u001b[0m\n",
      "\u001b[34m[05/21/2020 15:07:16 INFO 140130713106240] Epoch[4] Validation-accuracy=0.901961\u001b[0m\n",
      "\u001b[34m[05/21/2020 15:07:16 INFO 140130713106240] Storing the best model with validation accuracy: 0.901961\u001b[0m\n",
      "\u001b[34m[05/21/2020 15:07:16 INFO 140130713106240] Saved checkpoint to \"/opt/ml/model/image-classification-0005.params\"\u001b[0m\n",
      "\u001b[34m[05/21/2020 15:07:24 INFO 140130713106240] Epoch[5] Batch [20]#011Speed: 13.005 samples/sec#011accuracy=0.971429\u001b[0m\n",
      "\u001b[34m[05/21/2020 15:07:31 INFO 140130713106240] Epoch[5] Batch [40]#011Speed: 13.555 samples/sec#011accuracy=0.951220\u001b[0m\n",
      "\u001b[34m[05/21/2020 15:07:38 INFO 140130713106240] Epoch[5] Batch [60]#011Speed: 13.754 samples/sec#011accuracy=0.950820\u001b[0m\n",
      "\u001b[34m[05/21/2020 15:07:45 INFO 140130713106240] Epoch[5] Batch [80]#011Speed: 13.851 samples/sec#011accuracy=0.958025\u001b[0m\n",
      "\u001b[34m[05/21/2020 15:07:52 INFO 140130713106240] Epoch[5] Batch [100]#011Speed: 13.902 samples/sec#011accuracy=0.964356\u001b[0m\n",
      "\u001b[34m[05/21/2020 15:07:59 INFO 140130713106240] Epoch[5] Train-accuracy=0.968333\u001b[0m\n",
      "\u001b[34m[05/21/2020 15:07:59 INFO 140130713106240] Epoch[5] Time cost=42.696\u001b[0m\n",
      "\u001b[34m[05/21/2020 15:08:05 INFO 140130713106240] Epoch[5] Validation-accuracy=0.900000\u001b[0m\n",
      "\u001b[34m[05/21/2020 15:08:13 INFO 140130713106240] Epoch[6] Batch [20]#011Speed: 13.030 samples/sec#011accuracy=0.990476\u001b[0m\n",
      "\u001b[34m[05/21/2020 15:08:20 INFO 140130713106240] Epoch[6] Batch [40]#011Speed: 13.580 samples/sec#011accuracy=0.985366\u001b[0m\n",
      "\u001b[34m[05/21/2020 15:08:28 INFO 140130713106240] Epoch[6] Batch [60]#011Speed: 13.763 samples/sec#011accuracy=0.977049\u001b[0m\n",
      "\u001b[34m[05/21/2020 15:08:35 INFO 140130713106240] Epoch[6] Batch [80]#011Speed: 13.864 samples/sec#011accuracy=0.975309\u001b[0m\n",
      "\u001b[34m[05/21/2020 15:08:42 INFO 140130713106240] Epoch[6] Batch [100]#011Speed: 13.926 samples/sec#011accuracy=0.962376\u001b[0m\n",
      "\u001b[34m[05/21/2020 15:08:48 INFO 140130713106240] Epoch[6] Train-accuracy=0.963333\u001b[0m\n",
      "\u001b[34m[05/21/2020 15:08:48 INFO 140130713106240] Epoch[6] Time cost=42.610\u001b[0m\n",
      "\u001b[34m[05/21/2020 15:08:54 INFO 140130713106240] Epoch[6] Validation-accuracy=0.898039\u001b[0m\n",
      "\u001b[34m[05/21/2020 15:09:02 INFO 140130713106240] Epoch[7] Batch [20]#011Speed: 13.014 samples/sec#011accuracy=1.000000\u001b[0m\n",
      "\u001b[34m[05/21/2020 15:09:10 INFO 140130713106240] Epoch[7] Batch [40]#011Speed: 13.557 samples/sec#011accuracy=0.985366\u001b[0m\n",
      "\u001b[34m[05/21/2020 15:09:17 INFO 140130713106240] Epoch[7] Batch [60]#011Speed: 13.747 samples/sec#011accuracy=0.986885\u001b[0m\n",
      "\u001b[34m[05/21/2020 15:09:24 INFO 140130713106240] Epoch[7] Batch [80]#011Speed: 13.848 samples/sec#011accuracy=0.980247\u001b[0m\n",
      "\u001b[34m[05/21/2020 15:09:31 INFO 140130713106240] Epoch[7] Batch [100]#011Speed: 13.913 samples/sec#011accuracy=0.974257\u001b[0m\n",
      "\u001b[34m[05/21/2020 15:09:37 INFO 140130713106240] Epoch[7] Train-accuracy=0.975000\u001b[0m\n",
      "\u001b[34m[05/21/2020 15:09:37 INFO 140130713106240] Epoch[7] Time cost=42.650\u001b[0m\n",
      "\u001b[34m[05/21/2020 15:09:44 INFO 140130713106240] Epoch[7] Validation-accuracy=0.884615\u001b[0m\n",
      "\u001b[34m[05/21/2020 15:09:52 INFO 140130713106240] Epoch[8] Batch [20]#011Speed: 12.992 samples/sec#011accuracy=0.961905\u001b[0m\n",
      "\u001b[34m[05/21/2020 15:09:59 INFO 140130713106240] Epoch[8] Batch [40]#011Speed: 13.549 samples/sec#011accuracy=0.956098\u001b[0m\n",
      "\u001b[34m[05/21/2020 15:10:06 INFO 140130713106240] Epoch[8] Batch [60]#011Speed: 13.735 samples/sec#011accuracy=0.954098\u001b[0m\n",
      "\u001b[34m[05/21/2020 15:10:13 INFO 140130713106240] Epoch[8] Batch [80]#011Speed: 13.838 samples/sec#011accuracy=0.958025\u001b[0m\n",
      "\u001b[34m[05/21/2020 15:10:20 INFO 140130713106240] Epoch[8] Batch [100]#011Speed: 13.902 samples/sec#011accuracy=0.964356\u001b[0m\n",
      "\u001b[34m[05/21/2020 15:10:27 INFO 140130713106240] Epoch[8] Train-accuracy=0.958333\u001b[0m\n",
      "\u001b[34m[05/21/2020 15:10:27 INFO 140130713106240] Epoch[8] Time cost=42.682\u001b[0m\n",
      "\u001b[34m[05/21/2020 15:10:33 INFO 140130713106240] Epoch[8] Validation-accuracy=0.905882\u001b[0m\n",
      "\u001b[34m[05/21/2020 15:10:33 INFO 140130713106240] Storing the best model with validation accuracy: 0.905882\u001b[0m\n",
      "\u001b[34m[05/21/2020 15:10:33 INFO 140130713106240] Saved checkpoint to \"/opt/ml/model/image-classification-0009.params\"\u001b[0m\n",
      "\u001b[34m[05/21/2020 15:10:41 INFO 140130713106240] Epoch[9] Batch [20]#011Speed: 12.999 samples/sec#011accuracy=0.980952\u001b[0m\n",
      "\u001b[34m[05/21/2020 15:10:48 INFO 140130713106240] Epoch[9] Batch [40]#011Speed: 13.562 samples/sec#011accuracy=0.985366\u001b[0m\n",
      "\u001b[34m[05/21/2020 15:10:55 INFO 140130713106240] Epoch[9] Batch [60]#011Speed: 13.753 samples/sec#011accuracy=0.973770\u001b[0m\n",
      "\u001b[34m[05/21/2020 15:11:02 INFO 140130713106240] Epoch[9] Batch [80]#011Speed: 13.847 samples/sec#011accuracy=0.975309\u001b[0m\n",
      "\u001b[34m[05/21/2020 15:11:09 INFO 140130713106240] Epoch[9] Batch [100]#011Speed: 13.852 samples/sec#011accuracy=0.976238\u001b[0m\n",
      "\u001b[34m[05/21/2020 15:11:16 INFO 140130713106240] Epoch[9] Train-accuracy=0.975000\u001b[0m\n",
      "\u001b[34m[05/21/2020 15:11:16 INFO 140130713106240] Epoch[9] Time cost=42.809\u001b[0m\n",
      "\u001b[34m[05/21/2020 15:11:22 INFO 140130713106240] Epoch[9] Validation-accuracy=0.894118\u001b[0m\n",
      "\u001b[34m[05/21/2020 15:11:30 INFO 140130713106240] Epoch[10] Batch [20]#011Speed: 12.983 samples/sec#011accuracy=0.980952\u001b[0m\n",
      "\u001b[34m[05/21/2020 15:11:37 INFO 140130713106240] Epoch[10] Batch [40]#011Speed: 13.531 samples/sec#011accuracy=0.975610\u001b[0m\n",
      "\u001b[34m[05/21/2020 15:11:44 INFO 140130713106240] Epoch[10] Batch [60]#011Speed: 13.732 samples/sec#011accuracy=0.973770\u001b[0m\n",
      "\u001b[34m[05/21/2020 15:11:51 INFO 140130713106240] Epoch[10] Batch [80]#011Speed: 13.830 samples/sec#011accuracy=0.975309\u001b[0m\n",
      "\u001b[34m[05/21/2020 15:11:59 INFO 140130713106240] Epoch[10] Batch [100]#011Speed: 13.894 samples/sec#011accuracy=0.974257\u001b[0m\n",
      "\u001b[34m[05/21/2020 15:12:05 INFO 140130713106240] Epoch[10] Train-accuracy=0.975000\u001b[0m\n",
      "\u001b[34m[05/21/2020 15:12:05 INFO 140130713106240] Epoch[10] Time cost=42.700\u001b[0m\n",
      "\u001b[34m[05/21/2020 15:12:11 INFO 140130713106240] Epoch[10] Validation-accuracy=0.907692\u001b[0m\n",
      "\u001b[34m[05/21/2020 15:12:12 INFO 140130713106240] Storing the best model with validation accuracy: 0.907692\u001b[0m\n",
      "\u001b[34m[05/21/2020 15:12:12 INFO 140130713106240] Saved checkpoint to \"/opt/ml/model/image-classification-0011.params\"\u001b[0m\n",
      "\u001b[34m[05/21/2020 15:12:20 INFO 140130713106240] Epoch[11] Batch [20]#011Speed: 13.021 samples/sec#011accuracy=1.000000\u001b[0m\n",
      "\u001b[34m[05/21/2020 15:12:27 INFO 140130713106240] Epoch[11] Batch [40]#011Speed: 13.571 samples/sec#011accuracy=0.985366\u001b[0m\n",
      "\u001b[34m[05/21/2020 15:12:34 INFO 140130713106240] Epoch[11] Batch [60]#011Speed: 13.758 samples/sec#011accuracy=0.980328\u001b[0m\n",
      "\u001b[34m[05/21/2020 15:12:41 INFO 140130713106240] Epoch[11] Batch [80]#011Speed: 13.858 samples/sec#011accuracy=0.972840\u001b[0m\n",
      "\u001b[34m[05/21/2020 15:12:48 INFO 140130713106240] Epoch[11] Batch [100]#011Speed: 13.921 samples/sec#011accuracy=0.976238\u001b[0m\n",
      "\u001b[34m[05/21/2020 15:12:55 INFO 140130713106240] Epoch[11] Train-accuracy=0.978333\u001b[0m\n",
      "\u001b[34m[05/21/2020 15:12:55 INFO 140130713106240] Epoch[11] Time cost=42.622\u001b[0m\n",
      "\u001b[34m[05/21/2020 15:13:01 INFO 140130713106240] Epoch[11] Validation-accuracy=0.913725\u001b[0m\n",
      "\u001b[34m[05/21/2020 15:13:01 INFO 140130713106240] Storing the best model with validation accuracy: 0.913725\u001b[0m\n",
      "\u001b[34m[05/21/2020 15:13:01 INFO 140130713106240] Saved checkpoint to \"/opt/ml/model/image-classification-0012.params\"\u001b[0m\n",
      "\u001b[34m[05/21/2020 15:13:09 INFO 140130713106240] Epoch[12] Batch [20]#011Speed: 12.992 samples/sec#011accuracy=0.971429\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m[05/21/2020 15:13:16 INFO 140130713106240] Epoch[12] Batch [40]#011Speed: 13.545 samples/sec#011accuracy=0.975610\u001b[0m\n",
      "\u001b[34m[05/21/2020 15:13:23 INFO 140130713106240] Epoch[12] Batch [60]#011Speed: 13.721 samples/sec#011accuracy=0.977049\u001b[0m\n",
      "\u001b[34m[05/21/2020 15:13:30 INFO 140130713106240] Epoch[12] Batch [80]#011Speed: 13.818 samples/sec#011accuracy=0.980247\u001b[0m\n",
      "\u001b[34m[05/21/2020 15:13:37 INFO 140130713106240] Epoch[12] Batch [100]#011Speed: 13.851 samples/sec#011accuracy=0.984158\u001b[0m\n",
      "\u001b[34m[05/21/2020 15:13:44 INFO 140130713106240] Epoch[12] Train-accuracy=0.986667\u001b[0m\n",
      "\u001b[34m[05/21/2020 15:13:44 INFO 140130713106240] Epoch[12] Time cost=42.809\u001b[0m\n",
      "\u001b[34m[05/21/2020 15:13:50 INFO 140130713106240] Epoch[12] Validation-accuracy=0.884615\u001b[0m\n",
      "\u001b[34m[05/21/2020 15:13:58 INFO 140130713106240] Epoch[13] Batch [20]#011Speed: 12.983 samples/sec#011accuracy=0.990476\u001b[0m\n",
      "\u001b[34m[05/21/2020 15:14:06 INFO 140130713106240] Epoch[13] Batch [40]#011Speed: 13.528 samples/sec#011accuracy=0.985366\u001b[0m\n",
      "\u001b[34m[05/21/2020 15:14:13 INFO 140130713106240] Epoch[13] Batch [60]#011Speed: 13.721 samples/sec#011accuracy=0.986885\u001b[0m\n",
      "\u001b[34m[05/21/2020 15:14:20 INFO 140130713106240] Epoch[13] Batch [80]#011Speed: 13.819 samples/sec#011accuracy=0.982716\u001b[0m\n",
      "\u001b[34m[05/21/2020 15:14:27 INFO 140130713106240] Epoch[13] Batch [100]#011Speed: 13.878 samples/sec#011accuracy=0.980198\u001b[0m\n",
      "\u001b[34m[05/21/2020 15:14:33 INFO 140130713106240] Epoch[13] Train-accuracy=0.976667\u001b[0m\n",
      "\u001b[34m[05/21/2020 15:14:33 INFO 140130713106240] Epoch[13] Time cost=42.749\u001b[0m\n",
      "\u001b[34m[05/21/2020 15:14:39 INFO 140130713106240] Epoch[13] Validation-accuracy=0.909804\u001b[0m\n",
      "\u001b[34m[05/21/2020 15:14:48 INFO 140130713106240] Epoch[14] Batch [20]#011Speed: 12.999 samples/sec#011accuracy=0.990476\u001b[0m\n",
      "\u001b[34m[05/21/2020 15:14:55 INFO 140130713106240] Epoch[14] Batch [40]#011Speed: 13.565 samples/sec#011accuracy=0.995122\u001b[0m\n",
      "\u001b[34m[05/21/2020 15:15:02 INFO 140130713106240] Epoch[14] Batch [60]#011Speed: 13.757 samples/sec#011accuracy=0.993443\u001b[0m\n",
      "\u001b[34m[05/21/2020 15:15:09 INFO 140130713106240] Epoch[14] Batch [80]#011Speed: 13.858 samples/sec#011accuracy=0.992593\u001b[0m\n",
      "\u001b[34m[05/21/2020 15:15:16 INFO 140130713106240] Epoch[14] Batch [100]#011Speed: 13.927 samples/sec#011accuracy=0.986139\u001b[0m\n",
      "\u001b[34m[05/21/2020 15:15:23 INFO 140130713106240] Epoch[14] Train-accuracy=0.983333\u001b[0m\n",
      "\u001b[34m[05/21/2020 15:15:23 INFO 140130713106240] Epoch[14] Time cost=42.597\u001b[0m\n",
      "\u001b[34m[05/21/2020 15:15:28 INFO 140130713106240] Epoch[14] Validation-accuracy=0.890196\u001b[0m\n",
      "\u001b[34m[05/21/2020 15:15:37 INFO 140130713106240] Epoch[15] Batch [20]#011Speed: 13.041 samples/sec#011accuracy=0.961905\u001b[0m\n",
      "\u001b[34m[05/21/2020 15:15:44 INFO 140130713106240] Epoch[15] Batch [40]#011Speed: 13.578 samples/sec#011accuracy=0.975610\u001b[0m\n",
      "\u001b[34m[05/21/2020 15:15:51 INFO 140130713106240] Epoch[15] Batch [60]#011Speed: 13.769 samples/sec#011accuracy=0.977049\u001b[0m\n",
      "\u001b[34m[05/21/2020 15:15:58 INFO 140130713106240] Epoch[15] Batch [80]#011Speed: 13.870 samples/sec#011accuracy=0.980247\u001b[0m\n",
      "\u001b[34m[05/21/2020 15:16:05 INFO 140130713106240] Epoch[15] Batch [100]#011Speed: 13.929 samples/sec#011accuracy=0.982178\u001b[0m\n",
      "\u001b[34m[05/21/2020 15:16:12 INFO 140130713106240] Epoch[15] Train-accuracy=0.985000\u001b[0m\n",
      "\u001b[34m[05/21/2020 15:16:12 INFO 140130713106240] Epoch[15] Time cost=42.603\u001b[0m\n",
      "\u001b[34m[05/21/2020 15:16:18 INFO 140130713106240] Epoch[15] Validation-accuracy=0.915385\u001b[0m\n",
      "\u001b[34m[05/21/2020 15:16:18 INFO 140130713106240] Storing the best model with validation accuracy: 0.915385\u001b[0m\n",
      "\u001b[34m[05/21/2020 15:16:18 INFO 140130713106240] Saved checkpoint to \"/opt/ml/model/image-classification-0016.params\"\u001b[0m\n",
      "\u001b[34m[05/21/2020 15:16:26 INFO 140130713106240] Epoch[16] Batch [20]#011Speed: 12.993 samples/sec#011accuracy=0.990476\u001b[0m\n",
      "\u001b[34m[05/21/2020 15:16:33 INFO 140130713106240] Epoch[16] Batch [40]#011Speed: 13.571 samples/sec#011accuracy=0.995122\u001b[0m\n",
      "\u001b[34m[05/21/2020 15:16:40 INFO 140130713106240] Epoch[16] Batch [60]#011Speed: 13.758 samples/sec#011accuracy=0.996721\u001b[0m\n",
      "\u001b[34m[05/21/2020 15:16:47 INFO 140130713106240] Epoch[16] Batch [80]#011Speed: 13.863 samples/sec#011accuracy=0.997531\u001b[0m\n",
      "\u001b[34m[05/21/2020 15:16:54 INFO 140130713106240] Epoch[16] Batch [100]#011Speed: 13.897 samples/sec#011accuracy=0.998020\u001b[0m\n",
      "\u001b[34m[05/21/2020 15:17:01 INFO 140130713106240] Epoch[16] Train-accuracy=0.991667\u001b[0m\n",
      "\u001b[34m[05/21/2020 15:17:01 INFO 140130713106240] Epoch[16] Time cost=42.680\u001b[0m\n",
      "\u001b[34m[05/21/2020 15:17:07 INFO 140130713106240] Epoch[16] Validation-accuracy=0.894118\u001b[0m\n",
      "\u001b[34m[05/21/2020 15:17:15 INFO 140130713106240] Epoch[17] Batch [20]#011Speed: 13.053 samples/sec#011accuracy=0.980952\u001b[0m\n",
      "\u001b[34m[05/21/2020 15:17:22 INFO 140130713106240] Epoch[17] Batch [40]#011Speed: 13.604 samples/sec#011accuracy=0.970732\u001b[0m\n",
      "\u001b[34m[05/21/2020 15:17:29 INFO 140130713106240] Epoch[17] Batch [60]#011Speed: 13.807 samples/sec#011accuracy=0.977049\u001b[0m\n",
      "\u001b[34m[05/21/2020 15:17:36 INFO 140130713106240] Epoch[17] Batch [80]#011Speed: 13.911 samples/sec#011accuracy=0.977778\u001b[0m\n",
      "\u001b[34m[05/21/2020 15:17:43 INFO 140130713106240] Epoch[17] Batch [100]#011Speed: 13.977 samples/sec#011accuracy=0.976238\u001b[0m\n",
      "\u001b[34m[05/21/2020 15:17:50 INFO 140130713106240] Epoch[17] Train-accuracy=0.980000\u001b[0m\n",
      "\u001b[34m[05/21/2020 15:17:50 INFO 140130713106240] Epoch[17] Time cost=42.446\u001b[0m\n",
      "\u001b[34m[05/21/2020 15:17:56 INFO 140130713106240] Epoch[17] Validation-accuracy=0.907692\u001b[0m\n",
      "\u001b[34m[05/21/2020 15:18:04 INFO 140130713106240] Epoch[18] Batch [20]#011Speed: 13.033 samples/sec#011accuracy=0.980952\u001b[0m\n",
      "\u001b[34m[05/21/2020 15:18:11 INFO 140130713106240] Epoch[18] Batch [40]#011Speed: 13.583 samples/sec#011accuracy=0.990244\u001b[0m\n",
      "\u001b[34m[05/21/2020 15:18:18 INFO 140130713106240] Epoch[18] Batch [60]#011Speed: 13.784 samples/sec#011accuracy=0.990164\u001b[0m\n",
      "\u001b[34m[05/21/2020 15:18:25 INFO 140130713106240] Epoch[18] Batch [80]#011Speed: 13.881 samples/sec#011accuracy=0.987654\u001b[0m\n",
      "\u001b[34m[05/21/2020 15:18:32 INFO 140130713106240] Epoch[18] Batch [100]#011Speed: 13.947 samples/sec#011accuracy=0.990099\u001b[0m\n",
      "\u001b[34m[05/21/2020 15:18:39 INFO 140130713106240] Epoch[18] Train-accuracy=0.991667\u001b[0m\n",
      "\u001b[34m[05/21/2020 15:18:39 INFO 140130713106240] Epoch[18] Time cost=42.521\u001b[0m\n",
      "\u001b[34m[05/21/2020 15:18:45 INFO 140130713106240] Epoch[18] Validation-accuracy=0.917647\u001b[0m\n",
      "\u001b[34m[05/21/2020 15:18:45 INFO 140130713106240] Storing the best model with validation accuracy: 0.917647\u001b[0m\n",
      "\u001b[34m[05/21/2020 15:18:45 INFO 140130713106240] Saved checkpoint to \"/opt/ml/model/image-classification-0019.params\"\u001b[0m\n",
      "\u001b[34m[05/21/2020 15:18:53 INFO 140130713106240] Epoch[19] Batch [20]#011Speed: 13.017 samples/sec#011accuracy=1.000000\u001b[0m\n",
      "\u001b[34m[05/21/2020 15:19:00 INFO 140130713106240] Epoch[19] Batch [40]#011Speed: 13.570 samples/sec#011accuracy=0.985366\u001b[0m\n",
      "\u001b[34m[05/21/2020 15:19:07 INFO 140130713106240] Epoch[19] Batch [60]#011Speed: 13.760 samples/sec#011accuracy=0.983607\u001b[0m\n",
      "\u001b[34m[05/21/2020 15:19:14 INFO 140130713106240] Epoch[19] Batch [80]#011Speed: 13.872 samples/sec#011accuracy=0.987654\u001b[0m\n",
      "\u001b[34m[05/21/2020 15:19:21 INFO 140130713106240] Epoch[19] Batch [100]#011Speed: 13.908 samples/sec#011accuracy=0.988119\u001b[0m\n",
      "\u001b[34m[05/21/2020 15:19:28 INFO 140130713106240] Epoch[19] Train-accuracy=0.990000\u001b[0m\n",
      "\u001b[34m[05/21/2020 15:19:28 INFO 140130713106240] Epoch[19] Time cost=42.661\u001b[0m\n",
      "\u001b[34m[05/21/2020 15:19:34 INFO 140130713106240] Epoch[19] Validation-accuracy=0.921569\u001b[0m\n",
      "\u001b[34m[05/21/2020 15:19:34 INFO 140130713106240] Storing the best model with validation accuracy: 0.921569\u001b[0m\n",
      "\u001b[34m[05/21/2020 15:19:35 INFO 140130713106240] Saved checkpoint to \"/opt/ml/model/image-classification-0020.params\"\u001b[0m\n",
      "\u001b[34m[05/21/2020 15:19:42 INFO 140130713106240] Epoch[20] Batch [20]#011Speed: 12.985 samples/sec#011accuracy=1.000000\u001b[0m\n",
      "\u001b[34m[05/21/2020 15:19:50 INFO 140130713106240] Epoch[20] Batch [40]#011Speed: 13.554 samples/sec#011accuracy=0.975610\u001b[0m\n",
      "\u001b[34m[05/21/2020 15:19:57 INFO 140130713106240] Epoch[20] Batch [60]#011Speed: 13.722 samples/sec#011accuracy=0.983607\u001b[0m\n",
      "\u001b[34m[05/21/2020 15:20:04 INFO 140130713106240] Epoch[20] Batch [80]#011Speed: 13.825 samples/sec#011accuracy=0.987654\u001b[0m\n",
      "\u001b[34m[05/21/2020 15:20:11 INFO 140130713106240] Epoch[20] Batch [100]#011Speed: 13.870 samples/sec#011accuracy=0.988119\u001b[0m\n",
      "\u001b[34m[05/21/2020 15:20:18 INFO 140130713106240] Epoch[20] Train-accuracy=0.990000\u001b[0m\n",
      "\u001b[34m[05/21/2020 15:20:18 INFO 140130713106240] Epoch[20] Time cost=42.755\u001b[0m\n",
      "\u001b[34m[05/21/2020 15:20:24 INFO 140130713106240] Epoch[20] Validation-accuracy=0.900000\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m[05/21/2020 15:20:32 INFO 140130713106240] Epoch[21] Batch [20]#011Speed: 12.993 samples/sec#011accuracy=1.000000\u001b[0m\n",
      "\u001b[34m[05/21/2020 15:20:39 INFO 140130713106240] Epoch[21] Batch [40]#011Speed: 13.551 samples/sec#011accuracy=0.985366\u001b[0m\n",
      "\u001b[34m[05/21/2020 15:20:46 INFO 140130713106240] Epoch[21] Batch [60]#011Speed: 13.733 samples/sec#011accuracy=0.986885\u001b[0m\n",
      "\u001b[34m[05/21/2020 15:20:53 INFO 140130713106240] Epoch[21] Batch [80]#011Speed: 13.822 samples/sec#011accuracy=0.990123\u001b[0m\n",
      "\u001b[34m[05/21/2020 15:21:00 INFO 140130713106240] Epoch[21] Batch [100]#011Speed: 13.884 samples/sec#011accuracy=0.992079\u001b[0m\n",
      "\u001b[34m[05/21/2020 15:21:07 INFO 140130713106240] Epoch[21] Train-accuracy=0.993333\u001b[0m\n",
      "\u001b[34m[05/21/2020 15:21:07 INFO 140130713106240] Epoch[21] Time cost=42.738\u001b[0m\n",
      "\u001b[34m[05/21/2020 15:21:13 INFO 140130713106240] Epoch[21] Validation-accuracy=0.898039\u001b[0m\n",
      "\u001b[34m[05/21/2020 15:21:21 INFO 140130713106240] Epoch[22] Batch [20]#011Speed: 12.976 samples/sec#011accuracy=1.000000\u001b[0m\n",
      "\u001b[34m[05/21/2020 15:21:28 INFO 140130713106240] Epoch[22] Batch [40]#011Speed: 13.538 samples/sec#011accuracy=1.000000\u001b[0m\n",
      "\u001b[34m[05/21/2020 15:21:35 INFO 140130713106240] Epoch[22] Batch [60]#011Speed: 13.746 samples/sec#011accuracy=1.000000\u001b[0m\n",
      "\u001b[34m[05/21/2020 15:21:42 INFO 140130713106240] Epoch[22] Batch [80]#011Speed: 13.847 samples/sec#011accuracy=0.997531\u001b[0m\n",
      "\u001b[34m[05/21/2020 15:21:49 INFO 140130713106240] Epoch[22] Batch [100]#011Speed: 13.913 samples/sec#011accuracy=0.998020\u001b[0m\n",
      "\u001b[34m[05/21/2020 15:21:56 INFO 140130713106240] Epoch[22] Train-accuracy=0.998333\u001b[0m\n",
      "\u001b[34m[05/21/2020 15:21:56 INFO 140130713106240] Epoch[22] Time cost=42.675\u001b[0m\n",
      "\u001b[34m[05/21/2020 15:22:02 INFO 140130713106240] Epoch[22] Validation-accuracy=0.919231\u001b[0m\n",
      "\u001b[34m[05/21/2020 15:22:10 INFO 140130713106240] Epoch[23] Batch [20]#011Speed: 13.038 samples/sec#011accuracy=1.000000\u001b[0m\n",
      "\u001b[34m[05/21/2020 15:22:17 INFO 140130713106240] Epoch[23] Batch [40]#011Speed: 13.579 samples/sec#011accuracy=1.000000\u001b[0m\n",
      "\u001b[34m[05/21/2020 15:22:25 INFO 140130713106240] Epoch[23] Batch [60]#011Speed: 13.763 samples/sec#011accuracy=0.993443\u001b[0m\n",
      "\u001b[34m[05/21/2020 15:22:32 INFO 140130713106240] Epoch[23] Batch [80]#011Speed: 13.864 samples/sec#011accuracy=0.995062\u001b[0m\n",
      "\u001b[34m[05/21/2020 15:22:39 INFO 140130713106240] Epoch[23] Batch [100]#011Speed: 13.918 samples/sec#011accuracy=0.994059\u001b[0m\n",
      "\u001b[34m[05/21/2020 15:22:45 INFO 140130713106240] Epoch[23] Train-accuracy=0.995000\u001b[0m\n",
      "\u001b[34m[05/21/2020 15:22:45 INFO 140130713106240] Epoch[23] Time cost=42.636\u001b[0m\n",
      "\u001b[34m[05/21/2020 15:22:51 INFO 140130713106240] Epoch[23] Validation-accuracy=0.905882\u001b[0m\n",
      "\u001b[34m[05/21/2020 15:23:00 INFO 140130713106240] Epoch[24] Batch [20]#011Speed: 12.978 samples/sec#011accuracy=0.980952\u001b[0m\n",
      "\u001b[34m[05/21/2020 15:23:07 INFO 140130713106240] Epoch[24] Batch [40]#011Speed: 13.518 samples/sec#011accuracy=0.985366\u001b[0m\n",
      "\u001b[34m[05/21/2020 15:23:14 INFO 140130713106240] Epoch[24] Batch [60]#011Speed: 13.707 samples/sec#011accuracy=0.990164\u001b[0m\n",
      "\u001b[34m[05/21/2020 15:23:21 INFO 140130713106240] Epoch[24] Batch [80]#011Speed: 13.812 samples/sec#011accuracy=0.992593\u001b[0m\n",
      "\u001b[34m[05/21/2020 15:23:28 INFO 140130713106240] Epoch[24] Batch [100]#011Speed: 13.872 samples/sec#011accuracy=0.994059\u001b[0m\n",
      "\u001b[34m[05/21/2020 15:23:35 INFO 140130713106240] Epoch[24] Train-accuracy=0.995000\u001b[0m\n",
      "\u001b[34m[05/21/2020 15:23:35 INFO 140130713106240] Epoch[24] Time cost=42.761\u001b[0m\n",
      "\u001b[34m[05/21/2020 15:23:41 INFO 140130713106240] Epoch[24] Validation-accuracy=0.937255\u001b[0m\n",
      "\u001b[34m[05/21/2020 15:23:41 INFO 140130713106240] Storing the best model with validation accuracy: 0.937255\u001b[0m\n",
      "\u001b[34m[05/21/2020 15:23:41 INFO 140130713106240] Saved checkpoint to \"/opt/ml/model/image-classification-0025.params\"\u001b[0m\n",
      "\u001b[34m[05/21/2020 15:23:49 INFO 140130713106240] Epoch[25] Batch [20]#011Speed: 12.976 samples/sec#011accuracy=1.000000\u001b[0m\n",
      "\u001b[34m[05/21/2020 15:23:56 INFO 140130713106240] Epoch[25] Batch [40]#011Speed: 13.522 samples/sec#011accuracy=1.000000\u001b[0m\n",
      "\u001b[34m[05/21/2020 15:24:03 INFO 140130713106240] Epoch[25] Batch [60]#011Speed: 13.716 samples/sec#011accuracy=0.990164\u001b[0m\n",
      "\u001b[34m[05/21/2020 15:24:10 INFO 140130713106240] Epoch[25] Batch [80]#011Speed: 13.822 samples/sec#011accuracy=0.990123\u001b[0m\n",
      "\u001b[34m[05/21/2020 15:24:17 INFO 140130713106240] Epoch[25] Batch [100]#011Speed: 13.851 samples/sec#011accuracy=0.992079\u001b[0m\n",
      "\u001b[34m[05/21/2020 15:24:24 INFO 140130713106240] Epoch[25] Train-accuracy=0.990000\u001b[0m\n",
      "\u001b[34m[05/21/2020 15:24:24 INFO 140130713106240] Epoch[25] Time cost=42.802\u001b[0m\n",
      "\u001b[34m[05/21/2020 15:24:30 INFO 140130713106240] Epoch[25] Validation-accuracy=0.903846\u001b[0m\n",
      "\u001b[34m[05/21/2020 15:24:38 INFO 140130713106240] Epoch[26] Batch [20]#011Speed: 13.029 samples/sec#011accuracy=0.990476\u001b[0m\n",
      "\u001b[34m[05/21/2020 15:24:45 INFO 140130713106240] Epoch[26] Batch [40]#011Speed: 13.587 samples/sec#011accuracy=0.990244\u001b[0m\n",
      "\u001b[34m[05/21/2020 15:24:52 INFO 140130713106240] Epoch[26] Batch [60]#011Speed: 13.774 samples/sec#011accuracy=0.990164\u001b[0m\n",
      "\u001b[34m[05/21/2020 15:25:00 INFO 140130713106240] Epoch[26] Batch [80]#011Speed: 13.854 samples/sec#011accuracy=0.992593\u001b[0m\n",
      "\u001b[34m[05/21/2020 15:25:07 INFO 140130713106240] Epoch[26] Batch [100]#011Speed: 13.912 samples/sec#011accuracy=0.994059\u001b[0m\n",
      "\u001b[34m[05/21/2020 15:25:13 INFO 140130713106240] Epoch[26] Train-accuracy=0.995000\u001b[0m\n",
      "\u001b[34m[05/21/2020 15:25:13 INFO 140130713106240] Epoch[26] Time cost=42.661\u001b[0m\n",
      "\u001b[34m[05/21/2020 15:25:19 INFO 140130713106240] Epoch[26] Validation-accuracy=0.913725\u001b[0m\n",
      "\u001b[34m[05/21/2020 15:25:28 INFO 140130713106240] Epoch[27] Batch [20]#011Speed: 12.967 samples/sec#011accuracy=1.000000\u001b[0m\n",
      "\u001b[34m[05/21/2020 15:25:35 INFO 140130713106240] Epoch[27] Batch [40]#011Speed: 13.518 samples/sec#011accuracy=1.000000\u001b[0m\n",
      "\u001b[34m[05/21/2020 15:25:42 INFO 140130713106240] Epoch[27] Batch [60]#011Speed: 13.715 samples/sec#011accuracy=1.000000\u001b[0m\n",
      "\u001b[34m[05/21/2020 15:25:49 INFO 140130713106240] Epoch[27] Batch [80]#011Speed: 13.813 samples/sec#011accuracy=0.997531\u001b[0m\n",
      "\u001b[34m[05/21/2020 15:25:56 INFO 140130713106240] Epoch[27] Batch [100]#011Speed: 13.878 samples/sec#011accuracy=0.998020\u001b[0m\n",
      "\u001b[34m[05/21/2020 15:26:03 INFO 140130713106240] Epoch[27] Train-accuracy=0.998333\u001b[0m\n",
      "\u001b[34m[05/21/2020 15:26:03 INFO 140130713106240] Epoch[27] Time cost=42.763\u001b[0m\n",
      "\u001b[34m[05/21/2020 15:26:09 INFO 140130713106240] Epoch[27] Validation-accuracy=0.900000\u001b[0m\n",
      "\u001b[34m[05/21/2020 15:26:17 INFO 140130713106240] Epoch[28] Batch [20]#011Speed: 12.968 samples/sec#011accuracy=1.000000\u001b[0m\n",
      "\u001b[34m[05/21/2020 15:26:24 INFO 140130713106240] Epoch[28] Batch [40]#011Speed: 13.524 samples/sec#011accuracy=1.000000\u001b[0m\n",
      "\u001b[34m[05/21/2020 15:26:31 INFO 140130713106240] Epoch[28] Batch [60]#011Speed: 13.688 samples/sec#011accuracy=1.000000\u001b[0m\n",
      "\u001b[34m[05/21/2020 15:26:38 INFO 140130713106240] Epoch[28] Batch [80]#011Speed: 13.787 samples/sec#011accuracy=1.000000\u001b[0m\n",
      "\u001b[34m[05/21/2020 15:26:45 INFO 140130713106240] Epoch[28] Batch [100]#011Speed: 13.851 samples/sec#011accuracy=1.000000\u001b[0m\n",
      "\u001b[34m[05/21/2020 15:26:52 INFO 140130713106240] Epoch[28] Train-accuracy=1.000000\u001b[0m\n",
      "\u001b[34m[05/21/2020 15:26:52 INFO 140130713106240] Epoch[28] Time cost=42.838\u001b[0m\n",
      "\u001b[34m[05/21/2020 15:26:58 INFO 140130713106240] Epoch[28] Validation-accuracy=0.905882\u001b[0m\n",
      "\u001b[34m[05/21/2020 15:27:06 INFO 140130713106240] Epoch[29] Batch [20]#011Speed: 12.960 samples/sec#011accuracy=1.000000\u001b[0m\n",
      "\u001b[34m[05/21/2020 15:27:13 INFO 140130713106240] Epoch[29] Batch [40]#011Speed: 13.526 samples/sec#011accuracy=0.995122\u001b[0m\n",
      "\u001b[34m[05/21/2020 15:27:20 INFO 140130713106240] Epoch[29] Batch [60]#011Speed: 13.717 samples/sec#011accuracy=0.983607\u001b[0m\n",
      "\u001b[34m[05/21/2020 15:27:27 INFO 140130713106240] Epoch[29] Batch [80]#011Speed: 13.825 samples/sec#011accuracy=0.987654\u001b[0m\n",
      "\u001b[34m[05/21/2020 15:27:34 INFO 140130713106240] Epoch[29] Batch [100]#011Speed: 13.891 samples/sec#011accuracy=0.988119\u001b[0m\n",
      "\u001b[34m[05/21/2020 15:27:41 INFO 140130713106240] Epoch[29] Train-accuracy=0.990000\u001b[0m\n",
      "\u001b[34m[05/21/2020 15:27:41 INFO 140130713106240] Epoch[29] Time cost=42.715\u001b[0m\n",
      "\u001b[34m[05/21/2020 15:27:47 INFO 140130713106240] Epoch[29] Validation-accuracy=0.913725\u001b[0m\n",
      "\n",
      "2020-05-21 15:28:04 Uploading - Uploading generated training model\n",
      "2020-05-21 15:28:41 Completed - Training job completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training seconds: 1642\n",
      "Billable seconds: 1642\n",
      "\n",
      "\n",
      " Finished training! The model is available for download at: s3://sagemaker-us-east-2-693949087897/completeDataset/output/IC-completeDataset-1590073086/output/model.tar.gz\n",
      "CPU times: user 4.33 s, sys: 152 ms, total: 4.49 s\n",
      "Wall time: 30min 59s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "import time\n",
    "now = str(int(time.time()))\n",
    "training_job_name = 'IC-' + dataset_name.replace('_', '-') + '-' + now\n",
    "\n",
    "image_classifier.fit(inputs=data_channels, job_name=training_job_name, logs=True)\n",
    "\n",
    "job = image_classifier.latest_training_job\n",
    "model_path = f\"{base_dir}/{job.name}\"\n",
    "\n",
    "print(f\"\\n\\n Finished training! The model is available for download at: {image_classifier.output_path}/{job.name}/output/model.tar.gz\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deploy del modello trainato\n",
    "\n",
    "Una volta che il modello ha completato il train, utilizzeremo lo stesso oggetto dell'immagine (image_classifier) per creare un end-point completamente gestito."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------!CPU times: user 413 ms, sys: 1.16 ms, total: 415 ms\n",
      "Wall time: 11min 32s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Deploy del modello nell'end-point, può richiedere alcuni minuti\n",
    "\n",
    "deployed_endpoint = image_classifier.deploy(\n",
    "    initial_instance_count = 1,\n",
    "    instance_type = 'ml.t2.medium'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pulizia\n",
    "\n",
    "Quando abbiamo finito con l'end-point, possiamo eliminarlo e in questo modo le istanze di supporto verranno rilasciate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# deployed_endpoint.delete_endpoint()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Utilizzo dell' end-point appena deployato tramite codice Python\n",
    "\n",
    "Se si vuole utilizzare l'end-point di cui si è appena fatto il deploy, c'è una funzione da utilizzare, essa prende il percorso dell'immagine da classificare e la lista delle classi usate per il training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import json\n",
    "# import numpy as np\n",
    "# import os\n",
    "\n",
    "# def classify_deployed(file_name, classes):\n",
    "#     payload = None\n",
    "#     with open(file_name, 'rb') as f:\n",
    "#         payload = f.read()\n",
    "#         payload = bytearray(payload)\n",
    "        \n",
    "#     deployed_endpoint.content_type = 'application/x-image'\n",
    "#     result = json.loads(deployed_endpoint.predict(payload))\n",
    "#     best_prob_index = np.argmax(result)\n",
    "#     return (classes[best_prob_index], result[best_prob_index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inserire prova di evaluation\n",
    "\n",
    "# !aws s3 cp --recursive s3://ahlimgdata/test/ ./test/\n",
    "#%ls test\n",
    "\n",
    "# for img in os.listdir(\"test/\"):\n",
    "#     print(img)\n",
    "#     print(classify_deployed(\"test/\" + img,[\"change\", \"redcard\" , \"yellowcard\"]))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_mxnet_p36",
   "language": "python",
   "name": "conda_mxnet_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
